{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка XML файлов и извлечение предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xml_dataset(filename):\n",
    "    with open(filename, mode='r', encoding='windows-1251') as f_news:\n",
    "        xml = f_news.read()\n",
    "    \n",
    "    soup = BeautifulSoup(xml, 'lxml')\n",
    "    \n",
    "    dataset = []\n",
    "    for sent in soup.find_all('sentence'):\n",
    "        elem = sent.find('speech')\n",
    "        parsed = {\n",
    "            'id':     sent['id'],\n",
    "            'speach': elem['type'],\n",
    "            'data':   elem.text.strip(),\n",
    "            'eval':   sent.find('evaluation').text.strip(),\n",
    "            'url':    unescape(sent.find('url').text.strip())\n",
    "        }\n",
    "        if parsed['eval'] not in {'+', '-', '0'}:\n",
    "            continue\n",
    "        dataset.append(parsed)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_xml_dataset('news_sentiment_romip2012/train/news_eval_train.xml')\n",
    "data_test  = load_xml_dataset('news_sentiment_romip2012/test/news_eval_test.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Морфологическая предобработка предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "ru_morph = MorphAnalyzer()\n",
    "en_morph = WordNetLemmatizer()\n",
    "\n",
    "CYRILLIC_PATTERN = re.compile('[а-яА-Я]')\n",
    "DIGIT_PATTERN = re.compile('\\d+')\n",
    "\n",
    "def has_cyrillic(text):\n",
    "    return bool(CYRILLIC_PATTERN.search(text))\n",
    "\n",
    "def has_numeric(text):\n",
    "    return bool(DIGIT_PATTERN.search(text))\n",
    "\n",
    "@lru_cache(maxsize=1500)\n",
    "def morph_process(token):\n",
    "    if has_cyrillic(token):\n",
    "        return ru_morph.parse(token)[0].normal_form\n",
    "    elif has_numeric(token):\n",
    "        return token\n",
    "    else:\n",
    "        return en_morph.lemmatize(token)\n",
    "    \n",
    "def morph_sentence(sentence):\n",
    "    res = re.findall('\\d+', sentence.lower())\n",
    "    words = re.findall('[^\\W\\d_]+', sentence.lower())\n",
    "    res.extend(map(morph_process, words))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "ru_stopwords = stopwords.words('russian')\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "stopwords = set(ru_stopwords) | set(en_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train = [' '.join(morph_sentence(x['data'])) for x in data_train]\n",
    "sentences_test  = [' '.join(morph_sentence(x['data'])) for x in data_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_label(s):\n",
    "    return { '+': 1, '0': 0, '-': -1 }[s]\n",
    "\n",
    "y_train = np.asarray([modify_label(x['eval']) for x in data_train])\n",
    "y_test  = np.asarray([modify_label(x['eval']) for x in data_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 1864, 0: 914, 1: 1115}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(*np.unique(y_train, return_counts=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 1890, 0: 1235, 1: 1448}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(*np.unique(y_test, return_counts=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = {\n",
    "    ('binary', None):        CountVectorizer(binary=True),\n",
    "    ('binary', 'stopwords'): CountVectorizer(binary=True, stop_words=stopwords),\n",
    "    ('count', None):         CountVectorizer(binary=False),\n",
    "    ('count', 'stopwords'):  CountVectorizer(binary=False, stop_words=stopwords),\n",
    "    ('tfidf', None):         TfidfVectorizer(),\n",
    "    ('tfidf', 'stopwords'):  TfidfVectorizer(stop_words=stopwords),\n",
    "}\n",
    "\n",
    "for v in vectorizer.values():\n",
    "    v.fit(sentences_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(scores, type_):\n",
    "    format_str = r\"{:<6} | {:>9} | {:>9}\"\n",
    "    print(format_str.format('vector', 'stopwords', 'f1-measure'))\n",
    "    print('-' * 31)\n",
    "    \n",
    "    format_str = r\"{:<6} | {:>9} | {:>10.6f}\"\n",
    "    for k, v in scores.items():\n",
    "        if k[2] == type_:\n",
    "            print( format_str.format( k[0], k[1] == 'stopwords', v ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.2 s, sys: 351 ms, total: 8.55 s\n",
      "Wall time: 5.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for k, v in vectorizer.items():\n",
    "    cl = LogisticRegression(multi_class='ovr', max_iter=10_000, C=10)\n",
    "    \n",
    "    X_train = normalize(v.transform(sentences_train), norm='l2')\n",
    "    X_test  = normalize(v.transform(sentences_test), norm='l2')\n",
    "    \n",
    "    cl.fit(X_train, y_train)\n",
    "    y_pred = cl.predict(X_test)\n",
    "    \n",
    "    scores[(*k, 'micro')] = f1_score(y_test, y_pred, average='micro')\n",
    "    scores[(*k, 'macro')] = f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector | stopwords | f1-measure\n",
      "-------------------------------\n",
      "binary |         0 |   0.617538\n",
      "binary |         1 |   0.605729\n",
      "count  |         0 |   0.610321\n",
      "count  |         1 |   0.600700\n",
      "tfidf  |         0 |   0.616882\n",
      "tfidf  |         1 |   0.608791\n"
     ]
    }
   ],
   "source": [
    "print_scores(scores, 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector | stopwords | f1-measure\n",
      "-------------------------------\n",
      "binary |         0 |   0.581217\n",
      "binary |         1 |   0.571044\n",
      "count  |         0 |   0.572949\n",
      "count  |         1 |   0.565213\n",
      "tfidf  |         0 |   0.577080\n",
      "tfidf  |         1 |   0.569897\n"
     ]
    }
   ],
   "source": [
    "print_scores(scores, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.99 s, sys: 31.9 ms, total: 2.02 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for k, v in vectorizer.items():\n",
    "    if k[0] == 'tfidf':\n",
    "        continue\n",
    "    \n",
    "    if k[0] == 'binary':\n",
    "        cl = BernoulliNB(binarize=None)\n",
    "    else:\n",
    "        cl = MultinomialNB()\n",
    "    \n",
    "    X_train = v.transform(sentences_train)\n",
    "    X_test  = v.transform(sentences_test)\n",
    "    \n",
    "    cl.fit(X_train, y_train)\n",
    "    y_pred = cl.predict(X_test)\n",
    "    \n",
    "    scores[(*k, 'micro')] = f1_score(y_test, y_pred, average='micro')\n",
    "    scores[(*k, 'macro')] = f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector | stopwords | f1-measure\n",
      "-------------------------------\n",
      "binary |         0 |   0.600481\n",
      "binary |         1 |   0.587361\n",
      "count  |         0 |   0.637656\n",
      "count  |         1 |   0.624535\n"
     ]
    }
   ],
   "source": [
    "print_scores(scores, 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector | stopwords | f1-measure\n",
      "-------------------------------\n",
      "binary |         0 |   0.529937\n",
      "binary |         1 |   0.517345\n",
      "count  |         0 |   0.591538\n",
      "count  |         1 |   0.586111\n"
     ]
    }
   ],
   "source": [
    "print_scores(scores, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.16 s, sys: 71.9 ms, total: 9.23 s\n",
      "Wall time: 9.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for k, v in vectorizer.items():\n",
    "    cl = LinearSVC(max_iter=100_000, C=10)\n",
    "    \n",
    "    X_train = normalize(v.transform(sentences_train), norm='l2')\n",
    "    X_test  = normalize(v.transform(sentences_test), norm='l2')\n",
    "    \n",
    "    cl.fit(X_train, y_train)\n",
    "    y_pred = cl.predict(X_test)\n",
    "    \n",
    "    scores[(*k, 'micro')] = f1_score(y_test, y_pred, average='micro')\n",
    "    scores[(*k, 'macro')] = f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector | stopwords | f1-measure\n",
      "-------------------------------\n",
      "binary |         0 |   0.590859\n",
      "binary |         1 |   0.586049\n",
      "count  |         0 |   0.596764\n",
      "count  |         1 |   0.582768\n",
      "tfidf  |         0 |   0.597638\n",
      "tfidf  |         1 |   0.586923\n"
     ]
    }
   ],
   "source": [
    "print_scores(scores, 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector | stopwords | f1-measure\n",
      "-------------------------------\n",
      "binary |         0 |   0.565042\n",
      "binary |         1 |   0.563389\n",
      "count  |         0 |   0.571277\n",
      "count  |         1 |   0.559259\n",
      "tfidf  |         0 |   0.570190\n",
      "tfidf  |         1 |   0.560241\n"
     ]
    }
   ],
   "source": [
    "print_scores(scores, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 52s, sys: 6min 6s, total: 13min 59s\n",
      "Wall time: 12min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for k, v in vectorizer.items():\n",
    "    cl = MLPClassifier(hidden_layer_sizes=(1000, 200),\n",
    "                       early_stopping=True, max_iter=20,\n",
    "                       random_state=4444, verbose=1)\n",
    "    \n",
    "    X_train = normalize(v.transform(sentences_train), norm='l2')\n",
    "    X_test  = normalize(v.transform(sentences_test), norm='l2')\n",
    "    \n",
    "    cl.fit(X_train, y_train)\n",
    "    y_pred = cl.predict(X_test)\n",
    "    \n",
    "    scores[(*k, 'micro')] = f1_score(y_test, y_pred, average='micro')\n",
    "    scores[(*k, 'macro')] = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector | stopwords | f1-measure\n",
      "-------------------------------\n",
      "binary |         0 |   0.636781\n",
      "binary |         1 |   0.620818\n",
      "count  |         0 |   0.630658\n",
      "count  |         1 |   0.620162\n",
      "tfidf  |         0 |   0.632845\n",
      "tfidf  |         1 |   0.617975\n"
     ]
    }
   ],
   "source": [
    "print_scores(scores, 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector | stopwords | f1-measure\n",
      "-------------------------------\n",
      "binary |         0 |   0.593978\n",
      "binary |         1 |   0.574983\n",
      "count  |         0 |   0.591020\n",
      "count  |         1 |   0.575492\n",
      "tfidf  |         0 |   0.595804\n",
      "tfidf  |         1 |   0.569853\n"
     ]
    }
   ],
   "source": [
    "print_scores(scores, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
