{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote, urlparse, urlunparse, urljoin, unquote\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urlquote(url):\n",
    "    url_parsed = urlparse(url)\n",
    "    \n",
    "    url_parsed = OrderedDict(\n",
    "        (k, getattr(url_parsed, k))\n",
    "        for k in ['scheme', 'netloc', 'path', 'params', 'query', 'fragment'])\n",
    "    \n",
    "    for k in ['path', 'params', 'query', 'fragment']:\n",
    "        url_parsed[k] = quote(url_parsed[k])\n",
    "    \n",
    "    return urlunparse(url_parsed.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://ru.wikipedia.org/wiki/Проект:Знаете_ли_вы/Архив_рубрики/2018-06#19—22_июня'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(urlquote(url))\n",
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_page = soup.find('div', class_='mw-parser-output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter, itemgetter\n",
    "\n",
    "i_begin = None\n",
    "content, urls = [], []\n",
    "\n",
    "for child_i, child in enumerate(content_page.children):\n",
    "    if child.name == 'h2':\n",
    "        if child.find('span', class_='mw-headline', id=\"19—22_июня\"):\n",
    "            i_begin = child_i\n",
    "        elif i_begin is not None:\n",
    "            break\n",
    "    elif i_begin is not None and child.name == 'ul':\n",
    "        facts = child.find_all('li')\n",
    "        content.extend(map(attrgetter('text'), facts))\n",
    "        urls.extend(map(itemgetter('href'), child.find_all('a', href=True)))\n",
    "        \n",
    "urls = list(map(lambda u: urljoin('https://ru.wikipedia.org', u), urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for url in urls:\n",
    "    filename = unquote(urlparse(url).path)[6:]\n",
    "    filename = filename.replace(',', '')\n",
    "    filename = filename.replace('(', '').replace(')', '') + '.html'\n",
    "    filename = os.path.join(\"dumps\", filename)\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    with open(filename, mode='wb') as f_name:\n",
    "        f_name.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
